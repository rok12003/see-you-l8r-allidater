{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n",
      "1.26.0\n"
     ]
    }
   ],
   "source": [
    "# Import statements:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Checking versions:\n",
    "pd_version = pd.__version__\n",
    "np_version = np.__version__\n",
    "print(pd_version)\n",
    "print(np_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data:\n",
    "df = pd.read_csv(\"data/okcupid_profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59946.000000</td>\n",
       "      <td>59943.000000</td>\n",
       "      <td>59946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.340290</td>\n",
       "      <td>68.295281</td>\n",
       "      <td>20033.222534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.452779</td>\n",
       "      <td>3.994803</td>\n",
       "      <td>97346.192104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        height          income\n",
       "count  59946.000000  59943.000000    59946.000000\n",
       "mean      32.340290     68.295281    20033.222534\n",
       "std        9.452779      3.994803    97346.192104\n",
       "min       18.000000      1.000000       -1.000000\n",
       "25%       26.000000     66.000000       -1.000000\n",
       "50%       30.000000     68.000000       -1.000000\n",
       "75%       37.000000     71.000000       -1.000000\n",
       "max      110.000000     95.000000  1000000.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize function for numerical variables:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>job</th>\n",
       "      <th>...</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>59946</td>\n",
       "      <td>54650</td>\n",
       "      <td>35551</td>\n",
       "      <td>56961</td>\n",
       "      <td>45866</td>\n",
       "      <td>53318</td>\n",
       "      <td>54266</td>\n",
       "      <td>51748</td>\n",
       "      <td>...</td>\n",
       "      <td>54458</td>\n",
       "      <td>52374</td>\n",
       "      <td>50308</td>\n",
       "      <td>48470</td>\n",
       "      <td>49409</td>\n",
       "      <td>49096</td>\n",
       "      <td>46175</td>\n",
       "      <td>47495</td>\n",
       "      <td>40721</td>\n",
       "      <td>47343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>217</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>54347</td>\n",
       "      <td>51516</td>\n",
       "      <td>48625</td>\n",
       "      <td>43520</td>\n",
       "      <td>49257</td>\n",
       "      <td>48961</td>\n",
       "      <td>43583</td>\n",
       "      <td>45548</td>\n",
       "      <td>39323</td>\n",
       "      <td>45440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>enjoying it.</td>\n",
       "      <td>listening</td>\n",
       "      <td>my smile</td>\n",
       "      <td>ask me</td>\n",
       "      <td>family</td>\n",
       "      <td>my future</td>\n",
       "      <td>out with friends</td>\n",
       "      <td>ask me</td>\n",
       "      <td>you want to.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>55697</td>\n",
       "      <td>35829</td>\n",
       "      <td>51606</td>\n",
       "      <td>14652</td>\n",
       "      <td>16585</td>\n",
       "      <td>41780</td>\n",
       "      <td>37724</td>\n",
       "      <td>23959</td>\n",
       "      <td>32831</td>\n",
       "      <td>7589</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>82</td>\n",
       "      <td>529</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>161</td>\n",
       "      <td>89</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        status    sex orientation body_type             diet    drinks  drugs  \\\n",
       "count    59946  59946       59946     54650            35551     56961  45866   \n",
       "unique       5      2           3        12               18         6      3   \n",
       "top     single      m    straight   average  mostly anything  socially  never   \n",
       "freq     55697  35829       51606     14652            16585     41780  37724   \n",
       "\n",
       "                                education ethnicity    job  ... essay0  \\\n",
       "count                               53318     54266  51748  ...  54458   \n",
       "unique                                 32       217     21  ...  54347   \n",
       "top     graduated from college/university     white  other  ...      .   \n",
       "freq                                23959     32831   7589  ...     12   \n",
       "\n",
       "              essay1     essay2    essay3  essay4  essay5     essay6  \\\n",
       "count          52374      50308     48470   49409   49096      46175   \n",
       "unique         51516      48625     43520   49257   48961      43583   \n",
       "top     enjoying it.  listening  my smile  ask me  family  my future   \n",
       "freq              61         82       529      16       6        161   \n",
       "\n",
       "                  essay7  essay8        essay9  \n",
       "count              47495   40721         47343  \n",
       "unique             45548   39323         45440  \n",
       "top     out with friends  ask me  you want to.  \n",
       "freq                  89      45           200  \n",
       "\n",
       "[4 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary for categorical variables:\n",
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offspring      35561\n",
       "diet           24395\n",
       "religion       20226\n",
       "pets           19921\n",
       "essay8         19225\n",
       "drugs          14080\n",
       "essay6         13771\n",
       "essay9         12603\n",
       "essay7         12451\n",
       "essay3         11476\n",
       "sign           11056\n",
       "essay5         10850\n",
       "essay4         10537\n",
       "essay2          9638\n",
       "job             8198\n",
       "essay1          7572\n",
       "education       6628\n",
       "ethnicity       5680\n",
       "smokes          5512\n",
       "essay0          5488\n",
       "body_type       5296\n",
       "drinks          2985\n",
       "speaks            50\n",
       "height             3\n",
       "status             0\n",
       "location           0\n",
       "last_online        0\n",
       "income             0\n",
       "orientation        0\n",
       "sex                0\n",
       "age                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which columns have the least records:\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with just the essays:\n",
    "essays_df = df.loc[:, [\"essay0\", \"essay1\", \"essay2\", \"essay3\", \"essay4\", \n",
    "                   \"essay5\", \"essay6\", \"essay7\", \"essay8\", \"essay9\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/andrewmvd/okcupid-profiles/discussion/183145\n",
    "\n",
    "Ok--so these are what each essay prompt corresponds to. In order:\n",
    "\n",
    "1. essay0- My self summary\n",
    "2. essay1- What I’m doing with my life\n",
    "3. essay2- I’m really good at\n",
    "4. essay3- The first thing people usually notice about me\n",
    "5. essay4- Favorite books, movies, show, music, and food\n",
    "6. essay5- The six things I could never do without\n",
    "7. essay6- I spend a lot of time thinking about\n",
    "8. essay7- On a typical Friday night I am\n",
    "9. essay8- The most private thing I am willing to admit\n",
    "10. essay9- You should message me if...\n",
    "\n",
    "I'm unsure about what *order* the essays come in, but they mostly follow the pattern that essay0 is the most popular, and the latter essays are less popular. Essay #9 is the least popular, but overall--most people filled out the essay questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay0     5488\n",
       "essay1     7572\n",
       "essay2     9638\n",
       "essay4    10537\n",
       "essay5    10850\n",
       "essay3    11476\n",
       "essay7    12451\n",
       "essay9    12603\n",
       "essay6    13771\n",
       "essay8    19225\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which essays are the most to least popular:\n",
    "essays_df.isna().sum().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essay0    116.222226\n",
      "essay4     97.270335\n",
      "essay1     46.203192\n",
      "essay9     34.770969\n",
      "essay2     26.689214\n",
      "essay6     25.787071\n",
      "essay7     21.035456\n",
      "essay5     21.028801\n",
      "essay8     20.176052\n",
      "essay3     16.643883\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Tokenize essays into words and count the number of words\n",
    "word_counts = essays_df.apply(lambda x: x.str.split().str.len())\n",
    "\n",
    "# Calculate the average number of words per essay\n",
    "average_words_per_essay = word_counts.mean()\n",
    "print(average_words_per_essay.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essay #0 had significantly more words than the other essays, and is followed by essay #4, #1, and #9. Essay #8 continues to be on the \"low\" side of things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rohitkandala/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def most_popular_words(df):\n",
    "    \"\"\"\n",
    "    Calculates the ten most popular words in each essay column of the DataFrame, excluding stop words\n",
    "    \"\"\"\n",
    "    top_ten_per_column = {}\n",
    "\n",
    "    # Load stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for column in df.columns:\n",
    "        word_freq = Counter()  # Counter to store word frequencies for each column\n",
    "\n",
    "        # Iterate over each response in the column\n",
    "        for response in df[column]:\n",
    "            if isinstance(response, str):  # Check if the entry is a string\n",
    "                # Tokenize the essay into words\n",
    "                words = response.lower().split()  # Convert to lowercase and split into words\n",
    "\n",
    "                # Update word frequency counts for the column, excluding stop words\n",
    "                word_freq.update([word for word in words if word not in stop_words])\n",
    "\n",
    "        # Extract top ten words for the column\n",
    "        top_ten_words = [word for word, freq in word_freq.most_common(10)]\n",
    "\n",
    "        # Add top ten words for the column to the dictionary\n",
    "        top_ten_per_column[column] = top_ten_words\n",
    "\n",
    "    return top_ten_per_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in essay0: [\"i'm\", 'love', 'like', 'new', 'good', 'people', 'life', 'enjoy', 'time', 'also']\n",
      "Top 10 words in essay1: [\"i'm\", 'working', 'work', 'time', 'love', 'trying', 'like', 'new', 'life', 'also']\n",
      "Top 10 words in essay2: ['good', \"i'm\", 'making', 'people', 'things', 'really', '-', 'like', 'also', 'love']\n",
      "Top 10 words in essay3: [\"i'm\", 'people', 'smile', 'eyes', 'like', 'notice', 'really', 'look', 'hair', 'usually']\n",
      "Top 10 words in essay4: ['love', 'like', \"i'm\", '-', 'anything', 'favorite', 'music', 'music:', 'movies:', 'books:']\n",
      "Top 10 words in essay5: ['friends', 'family', '-', 'good', 'music', 'friends,', 'food', '1.', '2.', '3.']\n",
      "Top 10 words in essay6: [\"i'm\", 'next', 'think', 'life', 'people', 'things', 'like', 'time', 'want', 'going']\n",
      "Top 10 words in essay7: ['friends', 'home', 'watching', \"i'm\", 'going', 'friends,', 'dinner', 'friday', 'hanging', 'good']\n",
      "Top 10 words in essay8: [\"i'm\", 'like', 'really', 'know', 'love', 'get', 'private', 'think', \"i've\", 'one']\n",
      "Top 10 words in essay9: ['like', 'want', 'know', \"i'm\", 'good', 'looking', 'think', 'someone', 'get', '-']\n"
     ]
    }
   ],
   "source": [
    "top_words_per_column = most_popular_words(essays_df)\n",
    "\n",
    "for column, top_words in top_words_per_column.items():\n",
    "    print(f\"Top 10 words in {column}: {top_words}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
