{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ethan\\.conda\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ethan\\.conda\\envs\\nlp\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/okcupid_profiles.csv\")\n",
    "#df_sample = df.sample(1000).reset_index(drop = True)\n",
    "df_sample = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks',\n",
       "       'drugs', 'education', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'pets', 'religion', 'sign',\n",
       "       'smokes', 'speaks', 'essay0', 'essay1', 'essay2', 'essay3', 'essay4',\n",
       "       'essay5', 'essay6', 'essay7', 'essay8', 'essay9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All essays but essay9, which is \"you should message me if...\"\n",
    "\n",
    "df_demographics = df_sample[df_sample.columns.drop(list(df_sample.filter(regex=\"essay\")))]\n",
    "essays_df = df_sample.loc[:, [\"essay0\", \"essay1\", \"essay2\", \"essay3\", \"essay4\", \n",
    "                   \"essay5\", \"essay6\", \"essay7\", \"essay8\"]]\n",
    "essays_df = essays_df.fillna(\" \").astype(str)\n",
    "\n",
    "essays_df.loc[:, \"all_essays\"] = essays_df.apply(\" \".join, axis = 1)\n",
    "\n",
    "df_all = pd.concat([df_demographics, essays_df.loc[:, [\"all_essays\"]]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embedding_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_transformer_embeddings.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_array = np.load('sentence_transformer_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(target_vector, vectors):\n",
    "    similarities = []\n",
    "    for vector in vectors:\n",
    "        similarity = 1 - cosine(target_vector, vector)  # 1 - cosine distance to get cosine similarity\n",
    "        similarities.append(similarity)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"\"\"Return the first n items of the iterable as a list.\"\"\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_matches(input_bio, pref_gender=False, pref_age_lower=False, pref_age_higher=False, top_n=5):\n",
    "    df_possible = df_all.copy()\n",
    "    if pref_gender:\n",
    "        df_possible = df_possible.loc[df_possible.loc[:,'sex'] == pref_gender, :]\n",
    "    if pref_age_higher:\n",
    "        df_possible = df_possible[df_possible.loc[:, \"age\"] <= pref_age_higher]\n",
    "    if pref_age_lower:\n",
    "        df_possible = df_possible[df_possible.loc[:, \"age\"] >= pref_age_lower]\n",
    "\n",
    "\n",
    "    user_embeddings = model.encode(input_bio)\n",
    "\n",
    "    other_embeddings = [embedding_array[i] for i in df_possible.index]\n",
    "    # Compute the cosine similarity between the user's weighted embedding vector and all possible matches\n",
    "    cosine_similarities = compute_cosine_similarity(user_embeddings, other_embeddings)\n",
    "    # Recover index to match back to original dataframe\n",
    "    similarity_scores = {index:score for index, score in enumerate(cosine_similarities)}\n",
    "    # Sort by similarity\n",
    "    ranked_similarity = dict(sorted(similarity_scores.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "    top_match = take(5, ranked_similarity.items())\n",
    "\n",
    "    bios = [essays_df.loc[t[0], \"all_essays\"] for t in top_match]\n",
    "\n",
    "\n",
    "    return bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rank_matches(\"Test this for app usage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new to this app. what do you think?                ',\n",
       " 'just checking this app out                ',\n",
       " '  test              ',\n",
       " 'created for a/b testing. more data later.                ',\n",
       " 'i am trying this to see if my phone can help me find a match with this pof app. if it cannot i will blame the phone.  i am some italian, some belgian with a nice sense of humor. i am well traveled. i go to europe once a year. i have an accent. i recently came here from chicago. i like poetry. you could say i am romantic and sexy lol working hard...playing hard              ']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
