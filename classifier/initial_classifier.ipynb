{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_39560\\3979329272.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Users\\ethan\\.conda\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import statements:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Hugging face import:\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving zero-shot classification: \n",
    "theme_pipeline = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Saving sentiment pipeline\n",
    "# Ethan: specifying a model to ensure pipeline stability as per Huggingface recommendation\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = \"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in data:\n",
    "#df = pd.read_csv(\"/Users/amaribauer/Desktop/A_ML/FinalProject/okcupid_profiles.csv\")\n",
    "# Ethan: using a relative path for reproducability. To reproduce, add a data file in your home directory and put the profile document there.\n",
    "df = pd.read_csv(\"../data/okcupid_profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethan: sampling here rather than after data cleaning\n",
    "df_sample = df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essay dataframe:\n",
    "essays_df = df_sample.loc[:, [\"essay0\", \"essay1\", \"essay2\", \"essay3\", \"essay4\", \n",
    "                   \"essay5\", \"essay6\", \"essay7\", \"essay8\", \"essay9\"]]\n",
    "essays_df = essays_df.astype(str)\n",
    "\n",
    "# Essay0 dataframe only \"about me\":\n",
    "essay0_df = df_sample.loc[:, [\"essay0\"]]\n",
    "essay0_df = essay0_df.dropna(subset=['essay0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposed Additions to labels: travel, drinking, drugs, kids\n",
    "Proposed Removals: teen, enthusiastic, time periods, avid, miscellaneous, rock, sci-fi, favorite, novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting labels. Think of thse as our classes:\n",
    "# Ethan: Implemented Amari's suggestion for label names. We can tweak this more going forward.\n",
    "candidate_labels = ['TV', 'movies', 'music',\n",
    "          'comedies', 'food', 'drama',\n",
    "          'music', 'books', 'travel', 'drinking', \n",
    "          'drugs', 'kids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample of 10 observations:\n",
    "sampled_df = essay0_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([35730, 3187, 1451, 37917, 59844, 5013, 19058], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Checking indexes of dataframe that are included in the sample:\n",
    "print(sampled_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function helps with classification & making sure that tensors are all the\n",
    "# same length:\n",
    "\n",
    "def classify_essay(essay):\n",
    "\n",
    "    # Perform zero-shot classification\n",
    "    output = theme_pipeline(essay, candidate_labels)\n",
    "    \n",
    "    # Create a dictionary mapping labels to scores:\n",
    "    score_dict = {label: score for label, score in zip(\n",
    "        output['labels'], output['scores'])}\n",
    "    \n",
    "    # Ensure all candidate labels have a score, set to 0 if missing:\n",
    "    for label in candidate_labels:\n",
    "        if label not in score_dict:\n",
    "            score_dict[label] = 0.0\n",
    "    \n",
    "    # Convert the dictionary to a pandas Series:\n",
    "    return pd.Series(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying zero-shot classification to sampled dataframe & creating a dataframe:\n",
    "results = pd.concat([sampled_df['essay0'], sampled_df['essay0'].apply(classify_essay)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay0</th>\n",
       "      <th>travel</th>\n",
       "      <th>drama</th>\n",
       "      <th>kids</th>\n",
       "      <th>TV</th>\n",
       "      <th>music</th>\n",
       "      <th>comedies</th>\n",
       "      <th>drinking</th>\n",
       "      <th>movies</th>\n",
       "      <th>books</th>\n",
       "      <th>food</th>\n",
       "      <th>drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>i'm just a sweet, caring girl looking for what...</td>\n",
       "      <td>0.208246</td>\n",
       "      <td>0.173493</td>\n",
       "      <td>0.082750</td>\n",
       "      <td>0.081458</td>\n",
       "      <td>0.077048</td>\n",
       "      <td>0.073351</td>\n",
       "      <td>0.066264</td>\n",
       "      <td>0.046497</td>\n",
       "      <td>0.046491</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.020955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>my attempt at nutshell-ing myself:  i'm califo...</td>\n",
       "      <td>0.726675</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.006809</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.069811</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.046642</td>\n",
       "      <td>0.027142</td>\n",
       "      <td>0.030537</td>\n",
       "      <td>0.002358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49231</th>\n",
       "      <td>my name is katie - i grew up in loomis, ca - l...</td>\n",
       "      <td>0.596478</td>\n",
       "      <td>0.046295</td>\n",
       "      <td>0.049673</td>\n",
       "      <td>0.034879</td>\n",
       "      <td>0.057827</td>\n",
       "      <td>0.037907</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.026004</td>\n",
       "      <td>0.034496</td>\n",
       "      <td>0.017207</td>\n",
       "      <td>0.012556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44964</th>\n",
       "      <td>i'm independent, confident and self-sufficient...</td>\n",
       "      <td>0.620401</td>\n",
       "      <td>0.025246</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.027218</td>\n",
       "      <td>0.015264</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.218720</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.006818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41515</th>\n",
       "      <td>art, family, music, honest, friends, hate dram...</td>\n",
       "      <td>0.212720</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.252955</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.143121</td>\n",
       "      <td>0.119392</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39287</th>\n",
       "      <td>i'm a scientist, a financier, and an athlete. ...</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>0.031679</td>\n",
       "      <td>0.037775</td>\n",
       "      <td>0.042026</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>0.013645</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>0.740993</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.011627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41044</th>\n",
       "      <td>i like this quote from devilicia:\"she is the c...</td>\n",
       "      <td>0.028890</td>\n",
       "      <td>0.117876</td>\n",
       "      <td>0.023325</td>\n",
       "      <td>0.017396</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>0.031794</td>\n",
       "      <td>0.033540</td>\n",
       "      <td>0.012664</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>0.657713</td>\n",
       "      <td>0.015320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37621</th>\n",
       "      <td>i have been distracted by the economy, recentl...</td>\n",
       "      <td>0.100345</td>\n",
       "      <td>0.079656</td>\n",
       "      <td>0.026223</td>\n",
       "      <td>0.058697</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.027265</td>\n",
       "      <td>0.031049</td>\n",
       "      <td>0.028208</td>\n",
       "      <td>0.524672</td>\n",
       "      <td>0.019277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>i try not to sweat the small stuff, life is to...</td>\n",
       "      <td>0.154990</td>\n",
       "      <td>0.102214</td>\n",
       "      <td>0.093967</td>\n",
       "      <td>0.140970</td>\n",
       "      <td>0.081742</td>\n",
       "      <td>0.066150</td>\n",
       "      <td>0.046778</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.080555</td>\n",
       "      <td>0.051302</td>\n",
       "      <td>0.028376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30813</th>\n",
       "      <td>i don't think i can summarize myself. there ar...</td>\n",
       "      <td>0.102841</td>\n",
       "      <td>0.160372</td>\n",
       "      <td>0.116250</td>\n",
       "      <td>0.158108</td>\n",
       "      <td>0.071772</td>\n",
       "      <td>0.096163</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>0.050686</td>\n",
       "      <td>0.061501</td>\n",
       "      <td>0.035486</td>\n",
       "      <td>0.030176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  essay0    travel     drama  \\\n",
       "5868   i'm just a sweet, caring girl looking for what...  0.208246  0.173493   \n",
       "628    my attempt at nutshell-ing myself:  i'm califo...  0.726675  0.006837   \n",
       "49231  my name is katie - i grew up in loomis, ca - l...  0.596478  0.046295   \n",
       "44964  i'm independent, confident and self-sufficient...  0.620401  0.025246   \n",
       "41515  art, family, music, honest, friends, hate dram...  0.212720  0.007794   \n",
       "39287  i'm a scientist, a financier, and an athlete. ...  0.036069  0.031679   \n",
       "41044  i like this quote from devilicia:\"she is the c...  0.028890  0.117876   \n",
       "37621  i have been distracted by the economy, recentl...  0.100345  0.079656   \n",
       "14971  i try not to sweat the small stuff, life is to...  0.154990  0.102214   \n",
       "30813  i don't think i can summarize myself. there ar...  0.102841  0.160372   \n",
       "\n",
       "           kids        TV     music  comedies  drinking    movies     books  \\\n",
       "5868   0.082750  0.081458  0.077048  0.073351  0.066264  0.046497  0.046491   \n",
       "628    0.006809  0.005274  0.069811  0.003712  0.004391  0.046642  0.027142   \n",
       "49231  0.049673  0.034879  0.057827  0.037907  0.028851  0.026004  0.034496   \n",
       "44964  0.009919  0.022270  0.027218  0.015264  0.010547  0.218720  0.008975   \n",
       "41515  0.004008  0.000707  0.252955  0.000711  0.001258  0.143121  0.119392   \n",
       "39287  0.037775  0.042026  0.025607  0.013645  0.009025  0.013625  0.740993   \n",
       "41044  0.023325  0.017396  0.025175  0.031794  0.033540  0.012664  0.011132   \n",
       "37621  0.026223  0.058697  0.033626  0.037356  0.027265  0.031049  0.028208   \n",
       "14971  0.093967  0.140970  0.081742  0.066150  0.046778  0.071214  0.080555   \n",
       "30813  0.116250  0.158108  0.071772  0.096163  0.044873  0.050686  0.061501   \n",
       "\n",
       "           food     drugs  \n",
       "5868   0.046400  0.020955  \n",
       "628    0.030537  0.002358  \n",
       "49231  0.017207  0.012556  \n",
       "44964  0.007405  0.006818  \n",
       "41515  0.004099  0.000282  \n",
       "39287  0.012322  0.011627  \n",
       "41044  0.657713  0.015320  \n",
       "37621  0.524672  0.019277  \n",
       "14971  0.051302  0.028376  \n",
       "30813  0.035486  0.030176  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment for each essay0:\n",
    "def get_sentiment(essay):\n",
    "\n",
    "    # Run sentiment analysis on the essay text\n",
    "    sentiment_result = sentiment_pipeline(essay)\n",
    "\n",
    "    # Extract the sentiment label and score\n",
    "    label = sentiment_result[0]['label']\n",
    "    score = sentiment_result[0]['score']\n",
    "\n",
    "    # Return a dictionary with label and score\n",
    "    return {\n",
    "        'sentiment_label': label, 'sentiment_score': score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = [get_sentiment(essay) for essay in results.loc[:, 'essay0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks',\n",
       "       'drugs', 'education', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'pets', 'religion', 'sign',\n",
       "       'smokes', 'speaks', 'essay0', 'essay1', 'essay2', 'essay3', 'essay4',\n",
       "       'essay5', 'essay6', 'essay7', 'essay8', 'essay9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting everything together, so the output contains original biographical data, interest probabilities, and sentiment info\n",
    "df_label_sentiment = pd.concat([\n",
    "    df_sample.loc[:, ['age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks', 'drugs',\n",
    "                     'education', 'ethnicity', 'height', 'income', 'job', 'location',\n",
    "                     'offspring', 'pets', 'religion', 'sign', 'smokes', 'speaks']],\n",
    "    results], axis = 1).reset_index()\n",
    "\n",
    "df_label_sentiment = pd.concat([df_label_sentiment, pd.DataFrame(sentiment_dict)], axis = 1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'age', 'status', 'sex', 'orientation', 'body_type', 'diet',\n",
       "       'drinks', 'drugs', 'education', 'ethnicity', 'height', 'income', 'job',\n",
       "       'location', 'offspring', 'pets', 'religion', 'sign', 'smokes', 'speaks',\n",
       "       'essay0', 'drama', 'kids', 'travel', 'TV', 'drinking', 'comedies',\n",
       "       'movies', 'drugs', 'music', 'food', 'books', 'sentiment_label',\n",
       "       'sentiment_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_sentiment.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_sentiment.to_csv('classifier_outputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: Our end result here, sentiments_long, is a pandas df with the essay responses, the top themes, and sentiment analysis response for five essays. Our output for the eventual final classifier would a pandas dataframe with this information for every profile. An alternative implementation could be to include each essay, top theme, and sentiment into a tuple, and then we'd only have five columns per person instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- Saving probabilities into a dataset after computing all of them, consult with Ethan on the topic names prior to running everything\n",
    "\n",
    "----\n",
    "\n",
    "Generative AI portion:\n",
    "\n",
    "- import gpt-2 or some other model\n",
    "- fine tune model on the essays in the dataset\n",
    "- generate text in response to the input essay\n",
    "\n",
    "link with example of gpt2: https://huggingface.co/openai-community/gpt2\n",
    "\n",
    "- How do we incorporate higher matches to train the model? ## Ask the TA? \n",
    "    - One model is most likely feasible, but the best we have brain stormed is what if we do multiple models (one for each label)\n",
    "        - When user inputs text, classifier identifies top topic -> generate text in response with corresponding topic model\n",
    "\n",
    "-----\n",
    "\n",
    "Matching methodology:\n",
    "\n",
    "- One proposal: lets take the probabilities for each label between two individuals and compute the distance between the probabilities across ALL categories and aggregate them, that is the \"compatiability index\". \n",
    "    - Only conduct matching search for those who are compatiable, sexuality-wise\n",
    "        - Goal is to limit the amount of cross-computation\n",
    "    - Compute compatiability index ONLY between people who have the same top topic AND sexualtiy\n",
    "\n",
    "-----\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
