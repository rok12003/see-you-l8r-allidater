{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190da0e2c01745eeaf5e1a3bbf7afeed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd494a99a0a64ba79723c4f534503ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2447f647c234098a6161e29ddbba92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab7bac09ad34c64b66d54fbbf607ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e5da2094e04b7ab042162ef41c8167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd973b24dee43db807a76beb4ef9540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import statements:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Hugging face import:\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in data:\n",
    "df = pd.read_csv(\"/Users/rohitkandala/Desktop/UChicago/Academic Quarters/2023-24/Winter 2024/CAPP 30255/Project/okcupid_profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with just the essays:\n",
    "essays_df = df.loc[:, [\"essay0\", \"essay1\", \"essay2\", \"essay3\", \"essay4\", \n",
    "                   \"essay5\", \"essay6\", \"essay7\", \"essay8\", \"essay9\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining essays into 1 row per user:\n",
    "combined_series = (essays_df[\"essay0\"]\n",
    "    .str\n",
    "    .cat(essays_df.iloc[:]\n",
    "    .astype(str), sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write cleaning function that removes stopwords, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': \"about me:  i would love to think that i was some some kind of intellectual: either the dumbest smart guy, or the smartest dumb guy. can't say i can tell the difference. i love to talk about ideas and concepts. i forge odd metaphors instead of reciting cliches. like the simularities between a friend of mine's house and an underwater salt mine. my favorite word is salt by the way (weird choice i know). to me most things in life are better as metaphors. i seek to make myself a little better everyday, in some productively lazy way. got tired of tying my shoes. considered hiring a five year old, but would probably have to tie both of our shoes... decided to only wear leather shoes dress shoes.  about you:  you love to have really serious, really deep conversations about really silly stuff. you have to be willing to snap me out of a light hearted rant with a kiss. you don't have to be funny, but you have to be able to make me laugh. you should be able to bend spoons with your mind, and telepathically make me smile while i am still at work. you should love life, and be cool with just letting the wind blow. extra points for reading all this and guessing my favorite video game (no hints given yet). and lastly you have a good attention span. about me:  i would love to think that i was some some kind of intellectual: either the dumbest smart guy, or the smartest dumb guy. can't say i can tell the difference. i love to talk about ideas and concepts. i forge odd metaphors instead of reciting cliches. like the simularities between a friend of mine's house and an underwater salt mine. my favorite word is salt by the way (weird choice i know). to me most things in life are better as metaphors. i seek to make myself a little better everyday, in some productively lazy way. got tired of tying my shoes. considered hiring a five year old, but would probably have to tie both of our shoes... decided to only wear leather shoes dress shoes.  about you:  you love to have really serious, really deep conversations about really silly stuff. you have to be willing to snap me out of a light hearted rant with a kiss. you don't have to be funny, but you have to be able to make me laugh. you should be able to bend spoons with your mind, and telepathically make me smile while i am still at work. you should love life, and be cool with just letting the wind blow. extra points for reading all this and guessing my favorite video game (no hints given yet). and lastly you have a good attention span. currently working as an international agent for a freight forwarding company. import, export, domestic you know the works. online classes and trying to better myself in my free time. perhaps a hours worth of a good book or a video game on a lazy sunday. making people laugh. ranting about a good salting. finding simplicity in complexity, and complexity in simplicity. the way i look. i am a six foot half asian, half caucasian mutt. it makes it tough not to notice me, and for me to blend in. books: absurdistan, the republic, of mice and men (only book that made me want to cry), catcher in the rye, the prince.  movies: gladiator, operation valkyrie, the producers, down periscope.  shows: the borgia, arrested development, game of thrones, monty python  music: aesop rock, hail mary mallon, george thorogood and the delaware destroyers, felt  food: i'm down for anything. food. water. cell phone. shelter. duality and humorous things trying to find someone to hang out with. i am down for anything except a club. i am new to california and looking for someone to wisper my secrets to. you want to be swept off your feet! you are tired of the norm. you want to catch a coffee or a bite. or if you want to talk philosophy. about me:  i would love to think that i was some some kind of intellectual: either the dumbest smart guy, or the smartest dumb guy. can't say i can tell the difference. i love to talk about ideas and concepts. i forge odd metaphors instead of reciting cliches. like the simularities between a friend of mine's house and an underwater salt mine. my favorite word is salt by the way (weird choice i know). to me most things in life are better as metaphors. i seek to make myself a little better everyday, in some productively lazy way. got tired of tying my shoes. considered hiring a five year old, but would probably have to tie both of our shoes... decided to only wear leather shoes dress shoes.  about you:  you love to have really serious, really deep conversations about really silly stuff. you have to be willing to snap me out of a light hearted rant with a kiss. you don't have to be funny, but you have to be able to make me laugh. you should be able to bend spoons with your mind, and telepathically make me smile while i am still at work. you should love life, and be cool with just letting the wind blow. extra points for reading all this and guessing my favorite video game (no hints given yet). and lastly you have a good attention span.\",\n",
       " 'labels': ['like',\n",
       "  'miscellaneous',\n",
       "  'avid',\n",
       "  'favorite',\n",
       "  'enthusiastic',\n",
       "  'novelty',\n",
       "  'comedies',\n",
       "  'teen',\n",
       "  'time periods',\n",
       "  'rock',\n",
       "  'food',\n",
       "  'drama',\n",
       "  'everything',\n",
       "  'sci-fi',\n",
       "  'movies',\n",
       "  'music',\n",
       "  'music',\n",
       "  'books',\n",
       "  'TV hits'],\n",
       " 'scores': [0.10397571325302124,\n",
       "  0.09253178536891937,\n",
       "  0.08925922214984894,\n",
       "  0.08093003928661346,\n",
       "  0.07390537112951279,\n",
       "  0.07066534459590912,\n",
       "  0.0579424649477005,\n",
       "  0.0496620237827301,\n",
       "  0.04791715368628502,\n",
       "  0.04547489434480667,\n",
       "  0.04262462630867958,\n",
       "  0.04182051867246628,\n",
       "  0.037549570202827454,\n",
       "  0.029506107792258263,\n",
       "  0.029084619134664536,\n",
       "  0.028962893411517143,\n",
       "  0.028962893411517143,\n",
       "  0.02772328443825245,\n",
       "  0.021501503884792328]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifying sequences:\n",
    "sequence_to_classify = combined_series[0]\n",
    "candidate_labels = ['like', 'TV hits', 'enthusiastic', 'movies', 'music',\n",
    "          'comedies', 'food', 'teen', 'everything', 'drama', 'time periods', \n",
    "          'avid', 'miscellaneous', 'rock', 'music', 'sci-fi', 'favorite', \n",
    "          'novelty', 'books']\n",
    "\n",
    "# Inputting into classifer:\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- Saving probabilities into a dataset after computing all of them, consult with Ethan on the topic names prior to running everything\n",
    "\n",
    "----\n",
    "\n",
    "Generative AI portion:\n",
    "\n",
    "- import gpt-2 or some other model\n",
    "- fine tune model on the essays in the dataset\n",
    "- generate text in response to the input essay\n",
    "\n",
    "link with example of gpt2: https://huggingface.co/openai-community/gpt2\n",
    "\n",
    "- How do we incorporate higher matches to train the model? ## Ask the TA? \n",
    "    - One model is most likely feasible, but the best we have brain stormed is what if we do multiple models (one for each label)\n",
    "        - When user inputs text, classifier identifies top topic -> generate text in response with corresponding topic model\n",
    "\n",
    "-----\n",
    "\n",
    "Matching methodology:\n",
    "\n",
    "- One proposal: lets take the probabilities for each label between two individuals and compute the distance between the probabilities across ALL categories and aggregate them, that is the \"compatiability index\". \n",
    "    - Only conduct matching search for those who are compatiable, sexuality-wise\n",
    "        - Goal is to limit the amount of cross-computation\n",
    "    - Compute compatiability index ONLY between people who have the same top topic AND sexualtiy\n",
    "\n",
    "-----\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capp30255",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
