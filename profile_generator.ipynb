{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b54e476",
   "metadata": {},
   "source": [
    "This file details our efforts to compare a variety of different prompts and parameters in the use of a pretrained model to conduct few shot learning and generate a fake profile that sounds indistinguishable from other top matches.\n",
    "\n",
    "Different avenues explored include using:\n",
    "    - Full essays \n",
    "        - Example prompt:\n",
    "            Input: \n",
    "            Output:\n",
    "            Input:\n",
    "            Output:\n",
    "            Input:\n",
    "            \n",
    "    - First x number of characters of an essay\n",
    "            Example prompt: Same as above but cut off each essay after x characters\n",
    "            \n",
    "    - Good and bad match\n",
    "        - Example prompt:\n",
    "            This is the input essay: \n",
    "            This is a good match:\n",
    "            This is a bad match: \n",
    "            Write a new good match:\n",
    "            \n",
    "    - Experiment with different parameters of the generate function\n",
    "    \n",
    "    - different/larger versions of GPT - implement when we have more computational resources\n",
    "\n",
    "\n",
    "\n",
    "**NEED TO UPDATE This file loads in a pretrained model from the HuggingFace library, and uses most of an individuals essays and a csv containing the indices of their top match, to construct a prompt for a few shot encoder to produce a fake profile in the same style/tone that should also be a good match for them.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d15d3666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Obtaining dependency information for sentence_transformers from https://files.pythonhosted.org/packages/68/0d/27475988a3daade7516ea02dbc607b57d4a30f01bb49614a6430e76685c2/sentence_transformers-2.5.1-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (4.37.2)\n",
      "Requirement already satisfied: tqdm in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (2.0.0)\n",
      "Requirement already satisfied: numpy in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (0.20.3)\n",
      "Requirement already satisfied: Pillow in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: filelock in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/amaribauer/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: sentence_transformers\n",
      "Successfully installed sentence_transformers-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d87a080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb9e3ff38404ec58825e09030259f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cd79e28e0d4e94a10f9ec379709e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e8d6ad847d42ce9ebcfa9bbf4cd06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdbbfb10ad847ba8556634c776ab808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7faa2888144161b9223592062e560f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4a8287171245598db08e13d11afd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amaribauer/anaconda3/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903d9856d68447f2b38cce0698d1cfd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d381cf42c8b41458578661b57da4905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0713a10c6543488b7981784a2974e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad88301f1aba42a3bfa5129e7cb00b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6b4148a58c42c6927f39709bfca877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6a55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_new_input(input_str, pref_gender=False, pref_age_lower=False, pref_age_higher=False, min_similarity_score = 0.5):\n",
    "    df_possible = df_all.copy()\n",
    "    if pref_gender:\n",
    "        df_possible = df_possible.loc[df_possible.loc[:,'sex'] == pref_gender, :]\n",
    "    if pref_age_higher:\n",
    "        df_possible = df_possible[df_possible.loc[:, \"age\"] <= pref_age_higher]\n",
    "    if pref_age_lower:\n",
    "        df_possible = df_possible[df_possible.loc[:, \"age\"] >= pref_age_lower]\n",
    "    user_embeddings = model.encode(input_str)\n",
    "    other_embeddings = [embedding_series[i] for i in df_possible.index]\n",
    "    \n",
    "    # Compute the cosine similarity between the user's weighted embedding vector and all possible matches\n",
    "    cosine_similarities = compute_cosine_similarity(user_embeddings, other_embeddings)\n",
    "    # Recover index to match back to original dataframe\n",
    "    similarity_scores = [(df_possible.index[index], score) for index, score in enumerate(cosine_similarities) if score >= min_similarity_score and score != 1]\n",
    "    # Sort by similarity\n",
    "    ranked_similarity = sorted(similarity_scores, key = lambda x: x[1], reverse = True)\n",
    "    return ranked_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab202c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . . lynch, jarmusch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>...</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at: http://bagsbrown....</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians at the moment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>59</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>vibrant, expressive, caring optimist. i love b...</td>\n",
       "      <td>the happiest times have been when life came to...</td>\n",
       "      <td>i make an outstanding osso bucco. i am also ve...</td>\n",
       "      <td>i am told that people notice my smile, eyes an...</td>\n",
       "      <td>i am an avid movie watcher and follow the broa...</td>\n",
       "      <td>my family, my dog, italy, words and music!</td>\n",
       "      <td>writing my book.</td>\n",
       "      <td>running with my dog, finishing up the work wee...</td>\n",
       "      <td>i have a dream to sing at the alconquin in nyc...</td>\n",
       "      <td>you are seeking a long term connection of shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white, other</td>\n",
       "      <td>...</td>\n",
       "      <td>i'm nick. i never know what to write about mys...</td>\n",
       "      <td>currently finishing school for film production...</td>\n",
       "      <td>filmmaking, photography, graphic design, web d...</td>\n",
       "      <td>dude, i don't know.</td>\n",
       "      <td>movies: hook (the greatest adventure ever!), g...</td>\n",
       "      <td>iphone contact lenses headphones camera tv rem...</td>\n",
       "      <td>i do most of my thinking on the bus to/from wo...</td>\n",
       "      <td>bringin' home bacon, or drinking and shakin'!</td>\n",
       "      <td>when i was 18 i got a tattoo of waldo somewher...</td>\n",
       "      <td>meh if you made it this far you might as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>asian</td>\n",
       "      <td>...</td>\n",
       "      <td>hello! i enjoy traveling, watching movies, and...</td>\n",
       "      <td>i'm a civil engineer, who enjoys helping the c...</td>\n",
       "      <td>- looking at things objectively - getting thin...</td>\n",
       "      <td>i'm quiet until i get used to the environment ...</td>\n",
       "      <td>last book: \"game change\". movies: bourne serie...</td>\n",
       "      <td>- iphone - friends and family - internet - bay...</td>\n",
       "      <td>aside from work, how to improve my home.</td>\n",
       "      <td>out enjoying friendly conversation over dinner.</td>\n",
       "      <td>please let me think about this more.</td>\n",
       "      <td>we have similar interests.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, black</td>\n",
       "      <td>...</td>\n",
       "      <td>\"all i have in this world are my balls and my ...</td>\n",
       "      <td>following my dreams... \"you got a dream... you...</td>\n",
       "      <td>listening</td>\n",
       "      <td>it used to be the hair until i mowed it off bu...</td>\n",
       "      <td>where to begin musically: right now i listen t...</td>\n",
       "      <td>music, family, friends, a basketball, hoop, so...</td>\n",
       "      <td>what can i do to make someone chuckle....</td>\n",
       "      <td>what i would do on any other day. everydays a ...</td>\n",
       "      <td>i like walking around in other people's house ...</td>\n",
       "      <td>you are interested and interesting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>39</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>gay</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>is it odd that having a little \"enemy\" status ...</td>\n",
       "      <td>i work with elderly people (psychotherapy and ...</td>\n",
       "      <td>i'm a great bullshitter. i don't know what it ...</td>\n",
       "      <td>either that i am funny/sarcastic, or that i am...</td>\n",
       "      <td>i just read the help by kathryn stockett, sooo...</td>\n",
       "      <td>1. family &amp; friends &amp; other humans - interacti...</td>\n",
       "      <td>sex, myself, other people, how amazing everyth...</td>\n",
       "      <td>out at happy hour with my friends, running int...</td>\n",
       "      <td>i wish i could cry like holly hunter in broadc...</td>\n",
       "      <td>if you have a back-bone, an opinion, a sense o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     status sex orientation       body_type               diet  \\\n",
       "0       22     single   m    straight  a little extra  strictly anything   \n",
       "1       35     single   m    straight         average       mostly other   \n",
       "2       38  available   m    straight            thin           anything   \n",
       "3       23     single   m    straight            thin         vegetarian   \n",
       "4       29     single   m    straight        athletic                NaN   \n",
       "...    ...        ...  ..         ...             ...                ...   \n",
       "59941   59     single   f    straight             NaN                NaN   \n",
       "59942   24     single   m    straight             fit    mostly anything   \n",
       "59943   42     single   m    straight         average    mostly anything   \n",
       "59944   27     single   m    straight        athletic    mostly anything   \n",
       "59945   39     single   m         gay         average                NaN   \n",
       "\n",
       "           drinks      drugs                          education  \\\n",
       "0        socially      never      working on college/university   \n",
       "1           often  sometimes              working on space camp   \n",
       "2        socially        NaN     graduated from masters program   \n",
       "3        socially        NaN      working on college/university   \n",
       "4        socially      never  graduated from college/university   \n",
       "...           ...        ...                                ...   \n",
       "59941    socially      never  graduated from college/university   \n",
       "59942       often  sometimes      working on college/university   \n",
       "59943  not at all      never     graduated from masters program   \n",
       "59944    socially      often      working on college/university   \n",
       "59945    socially        NaN     graduated from masters program   \n",
       "\n",
       "                 ethnicity  ...  \\\n",
       "0             asian, white  ...   \n",
       "1                    white  ...   \n",
       "2                      NaN  ...   \n",
       "3                    white  ...   \n",
       "4      asian, black, other  ...   \n",
       "...                    ...  ...   \n",
       "59941                  NaN  ...   \n",
       "59942         white, other  ...   \n",
       "59943                asian  ...   \n",
       "59944         asian, black  ...   \n",
       "59945                white  ...   \n",
       "\n",
       "                                                  essay0  \\\n",
       "0      about me:  i would love to think that i was so...   \n",
       "1      i am a chef: this is what that means. 1. i am ...   \n",
       "2      i'm not ashamed of much, but writing public te...   \n",
       "3              i work in a library and go to school. . .   \n",
       "4      hey how's it going? currently vague on the pro...   \n",
       "...                                                  ...   \n",
       "59941  vibrant, expressive, caring optimist. i love b...   \n",
       "59942  i'm nick. i never know what to write about mys...   \n",
       "59943  hello! i enjoy traveling, watching movies, and...   \n",
       "59944  \"all i have in this world are my balls and my ...   \n",
       "59945  is it odd that having a little \"enemy\" status ...   \n",
       "\n",
       "                                                  essay1  \\\n",
       "0      currently working as an international agent fo...   \n",
       "1      dedicating everyday to being an unbelievable b...   \n",
       "2      i make nerdy software for musicians, artists, ...   \n",
       "3              reading things written by old dead people   \n",
       "4                             work work work work + play   \n",
       "...                                                  ...   \n",
       "59941  the happiest times have been when life came to...   \n",
       "59942  currently finishing school for film production...   \n",
       "59943  i'm a civil engineer, who enjoys helping the c...   \n",
       "59944  following my dreams... \"you got a dream... you...   \n",
       "59945  i work with elderly people (psychotherapy and ...   \n",
       "\n",
       "                                                  essay2  \\\n",
       "0      making people laugh. ranting about a good salt...   \n",
       "1      being silly. having ridiculous amonts of fun w...   \n",
       "2      improvising in different contexts. alternating...   \n",
       "3      playing synthesizers and organizing books acco...   \n",
       "4      creating imagery to look at: http://bagsbrown....   \n",
       "...                                                  ...   \n",
       "59941  i make an outstanding osso bucco. i am also ve...   \n",
       "59942  filmmaking, photography, graphic design, web d...   \n",
       "59943  - looking at things objectively - getting thin...   \n",
       "59944                                          listening   \n",
       "59945  i'm a great bullshitter. i don't know what it ...   \n",
       "\n",
       "                                                  essay3  \\\n",
       "0      the way i look. i am a six foot half asian, ha...   \n",
       "1                                                    NaN   \n",
       "2      my large jaw and large glasses are the physica...   \n",
       "3                      socially awkward but i do my best   \n",
       "4                i smile a lot and my inquisitive nature   \n",
       "...                                                  ...   \n",
       "59941  i am told that people notice my smile, eyes an...   \n",
       "59942                                dude, i don't know.   \n",
       "59943  i'm quiet until i get used to the environment ...   \n",
       "59944  it used to be the hair until i mowed it off bu...   \n",
       "59945  either that i am funny/sarcastic, or that i am...   \n",
       "\n",
       "                                                  essay4  \\\n",
       "0      books: absurdistan, the republic, of mice and ...   \n",
       "1      i am die hard christopher moore fan. i don't r...   \n",
       "2      okay this is where the cultural matrix gets so...   \n",
       "3      bataille, celine, beckett. . . lynch, jarmusch...   \n",
       "4      music: bands, rappers, musicians at the moment...   \n",
       "...                                                  ...   \n",
       "59941  i am an avid movie watcher and follow the broa...   \n",
       "59942  movies: hook (the greatest adventure ever!), g...   \n",
       "59943  last book: \"game change\". movies: bourne serie...   \n",
       "59944  where to begin musically: right now i listen t...   \n",
       "59945  i just read the help by kathryn stockett, sooo...   \n",
       "\n",
       "                                                  essay5  \\\n",
       "0                      food. water. cell phone. shelter.   \n",
       "1      delicious porkness in all of its glories. my b...   \n",
       "2      movement conversation creation contemplation t...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941         my family, my dog, italy, words and music!   \n",
       "59942  iphone contact lenses headphones camera tv rem...   \n",
       "59943  - iphone - friends and family - internet - bay...   \n",
       "59944  music, family, friends, a basketball, hoop, so...   \n",
       "59945  1. family & friends & other humans - interacti...   \n",
       "\n",
       "                                                  essay6  \\\n",
       "0                            duality and humorous things   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                             cats and german philosophy   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941                                   writing my book.   \n",
       "59942  i do most of my thinking on the bus to/from wo...   \n",
       "59943           aside from work, how to improve my home.   \n",
       "59944          what can i do to make someone chuckle....   \n",
       "59945  sex, myself, other people, how amazing everyth...   \n",
       "\n",
       "                                                  essay7  \\\n",
       "0      trying to find someone to hang out with. i am ...   \n",
       "1                                                    NaN   \n",
       "2      viewing. listening. dancing. talking. drinking...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941  running with my dog, finishing up the work wee...   \n",
       "59942      bringin' home bacon, or drinking and shakin'!   \n",
       "59943    out enjoying friendly conversation over dinner.   \n",
       "59944  what i would do on any other day. everydays a ...   \n",
       "59945  out at happy hour with my friends, running int...   \n",
       "\n",
       "                                                  essay8  \\\n",
       "0      i am new to california and looking for someone...   \n",
       "1      i am very open and will share just about anyth...   \n",
       "2      when i was five years old, i was known as \"the...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941  i have a dream to sing at the alconquin in nyc...   \n",
       "59942  when i was 18 i got a tattoo of waldo somewher...   \n",
       "59943               please let me think about this more.   \n",
       "59944  i like walking around in other people's house ...   \n",
       "59945  i wish i could cry like holly hunter in broadc...   \n",
       "\n",
       "                                                  essay9  \n",
       "0      you want to be swept off your feet! you are ti...  \n",
       "1                                                    NaN  \n",
       "2      you are bright, open, intense, silly, ironic, ...  \n",
       "3                                  you feel so inclined.  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "59941  you are seeking a long term connection of shar...  \n",
       "59942     meh if you made it this far you might as well.  \n",
       "59943                         we have similar interests.  \n",
       "59944              you are interested and interesting...  \n",
       "59945  if you have a back-bone, an opinion, a sense o...  \n",
       "\n",
       "[59946 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('./okcupid_profiles.csv')\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880f1622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55435</th>\n",
       "      <td>[0.020514823496341705, -0.09198534488677979, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31346</th>\n",
       "      <td>[-0.03974509984254837, -0.09139120578765869, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23575</th>\n",
       "      <td>[0.018866078928112984, -0.0564219132065773, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37715</th>\n",
       "      <td>[0.11587301641702652, -0.05597995966672897, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58384</th>\n",
       "      <td>[0.002988251158967614, -0.07680206745862961, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43905</th>\n",
       "      <td>[0.08724702894687653, -0.07293721288442612, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33153</th>\n",
       "      <td>[0.000331356655806303, -0.07900834828615189, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7678</th>\n",
       "      <td>[-0.02853960171341896, -0.014243010431528091, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>[0.07088251411914825, -0.0943324938416481, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58823</th>\n",
       "      <td>[0.0614720843732357, -0.07788537442684174, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    embedding\n",
       "Unnamed: 0                                                   \n",
       "55435       [0.020514823496341705, -0.09198534488677979, 0...\n",
       "31346       [-0.03974509984254837, -0.09139120578765869, -...\n",
       "23575       [0.018866078928112984, -0.0564219132065773, 0....\n",
       "37715       [0.11587301641702652, -0.05597995966672897, 0....\n",
       "58384       [0.002988251158967614, -0.07680206745862961, 0...\n",
       "...                                                       ...\n",
       "43905       [0.08724702894687653, -0.07293721288442612, 0....\n",
       "33153       [0.000331356655806303, -0.07900834828615189, 0...\n",
       "7678        [-0.02853960171341896, -0.014243010431528091, ...\n",
       "2534        [0.07088251411914825, -0.0943324938416481, 0.0...\n",
       "58823       [0.0614720843732357, -0.07788537442684174, 0.0...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_series = pd.read_csv('./embedding_series.csv').set_index('Unnamed: 0')\n",
    "embedding_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "556feb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_input_matches = rank_new_input(\"I like bacon and pumpkin pie\",'f', 30,40, 0.2)\n",
    "#returns list of tuples, possibly as strings for some weird reason\n",
    "#TEMPORARY USE WHILE BUILDING CONSTRUCT_PROMPT. \n",
    "matches = pd.read_csv('./okcupid_matches.csv').set_index('Unnamed: 0')\n",
    "\n",
    "new_input_matches = matches.loc[55435]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2a98e4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ast\n",
      "  Using cached AST-0.0.2.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[8 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/0c/ytgqby892k1dcqcnn5gw20f00000gn/T/pip-install-qb_355ty/ast_c646a82fc6b34059bf43387d83fad06a/setup.py\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m     README = codecs.open(os.path.join(here, 'AST/README'), encoding='utf8').read()\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"<frozen codecs>\", line 906, in open\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/private/var/folders/0c/ytgqby892k1dcqcnn5gw20f00000gn/T/pip-install-qb_355ty/ast_c646a82fc6b34059bf43387d83fad06a/AST/README'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(57837, 0.7229513275538625),\n",
       " (32304, 0.720553979275116),\n",
       " (41271, 0.7122389466715242),\n",
       " (55723, 0.709845422683183),\n",
       " (24577, 0.7035214856643491),\n",
       " (24856, 0.6980997502248912),\n",
       " (35073, 0.6934971323052491),\n",
       " (28629, 0.6934001708037837),\n",
       " (35770, 0.6870449508390966),\n",
       " (53961, 0.6858659544974753),\n",
       " (39454, 0.6849265506596943),\n",
       " (16522, 0.6840750659184236),\n",
       " (7566, 0.683595228220249),\n",
       " (45458, 0.6816629166865934),\n",
       " (10579, 0.680168197082343),\n",
       " (44456, 0.6800201338679456),\n",
       " (1024, 0.6791760733160084),\n",
       " (34206, 0.6791658206279321),\n",
       " (37079, 0.677791299052506),\n",
       " (23705, 0.6776834040308605),\n",
       " (36446, 0.6771668823965459),\n",
       " (4833, 0.6765438008229576),\n",
       " (12738, 0.6760975057045089),\n",
       " (26765, 0.6759330847577657),\n",
       " (10691, 0.6758259416378812),\n",
       " (24471, 0.6744851405268925),\n",
       " (17928, 0.6742697746069406),\n",
       " (31221, 0.673574951323189),\n",
       " (1038, 0.673137020306301),\n",
       " (53875, 0.6723775170263808),\n",
       " (28240, 0.6718561919399977),\n",
       " (20197, 0.6715672368087098),\n",
       " (14038, 0.6702798080782724),\n",
       " (51290, 0.670005548306794),\n",
       " (50694, 0.6699648816145607),\n",
       " (46601, 0.6698167622044707),\n",
       " (2039, 0.6681750176904283),\n",
       " (18498, 0.6674061139733727),\n",
       " (2986, 0.6671720895056162),\n",
       " (45182, 0.665198533639204),\n",
       " (54882, 0.6644888724165232),\n",
       " (57797, 0.6642078526309121),\n",
       " (56114, 0.6628914090713058),\n",
       " (31048, 0.6626294530660564),\n",
       " (6712, 0.6620064968039623),\n",
       " (39522, 0.6619818837755346),\n",
       " (11352, 0.6614747390179663),\n",
       " (22902, 0.6610714566482209),\n",
       " (48444, 0.6609728376392174),\n",
       " (19170, 0.6609493236897228),\n",
       " (43112, 0.6609284830207401),\n",
       " (47474, 0.6608443280530327),\n",
       " (53510, 0.6606947700951503),\n",
       " (14922, 0.660546034574903),\n",
       " (25026, 0.6597009391959001),\n",
       " (36312, 0.6595255695297434),\n",
       " (32659, 0.6589810199893764),\n",
       " (23753, 0.6588031389447953),\n",
       " (39209, 0.6581816446260383),\n",
       " (44126, 0.6575153166615021),\n",
       " (40573, 0.6568279045637213),\n",
       " (2551, 0.6556693676835779),\n",
       " (15715, 0.6556459754342941),\n",
       " (33620, 0.6552776027089999),\n",
       " (6941, 0.6547130902949181),\n",
       " (7310, 0.653711964593004),\n",
       " (34924, 0.6529218612632468),\n",
       " (18047, 0.6527603044409859),\n",
       " (4098, 0.6524451245835359),\n",
       " (34695, 0.6523745341549056),\n",
       " (45168, 0.652374030749933),\n",
       " (42868, 0.6521544954851808),\n",
       " (31472, 0.651547118340983),\n",
       " (37664, 0.6515078669069935),\n",
       " (58384, 0.651458481695797),\n",
       " (47313, 0.6505535138397669),\n",
       " (44128, 0.6503781342274624)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install ast\n",
    "from ast import literal_eval\n",
    "new_input_matches = literal_eval(new_input_matches['matches'])\n",
    "new_input_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d355a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(input_string, matches, num_char = False):\n",
    "    slice_len = min(2, len(matches))\n",
    "    top_matches_slice = matches[:slice_len]\n",
    "    essays_to_use = [\"essay0\", \"essay1\", \"essay2\", \"essay3\", \"essay4\", \n",
    "                   \"essay5\", \"essay6\", \"essay7\", \"essay8\"]\n",
    "    prompt = 'Write a dating profile that would be a good match for the input person ' + \"Input: \" + input_string\n",
    "    for i, val in top_matches_slice:\n",
    "        essays_subset = df_all.loc[i,essays_to_use]\n",
    "        output = essays_subset.str.cat()\n",
    "        if num_char:\n",
    "            output = output[:num_char]\n",
    "        prompt = prompt  + f\" Top Match {i + 1}: \" + output\n",
    "    return prompt + f\"Input: {input_string}\" + \" New Profile: \"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e14f73f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a dating profile that would be a good match for the input person Input: Hey there! I'm Jimmy, but you can call me Jim. \\nI'm a curious soul with a zest for life and a passion for adventure. By day, I'm a data scientist, \\nbut by night, I'm a dreamer exploring the wonders of the world, both near and far. Top Match 57838: i'm addicted to caffeine. i collect random old photographs. i am a master procrastinator and a pop culture junkie. i love philip marlowe. i am currently going through a knitting phase, although someti Top Match 32305: a large portion of my life is consumed by sarcastic jokes, photography, web design, and over thinking simple situations. the other 10% is spent untangling my headphones, cleaning clothes in my never eInput: Hey there! I'm Jimmy, but you can call me Jim. \\nI'm a curious soul with a zest for life and a passion for adventure. By day, I'm a data scientist, \\nbut by night, I'm a dreamer exploring the wonders of the world, both near and far. New Profile: \""
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str = \"\"\"Hey there! I'm Jimmy, but you can call me Jim. \n",
    "I'm a curious soul with a zest for life and a passion for adventure. By day, I'm a data scientist, \n",
    "but by night, I'm a dreamer exploring the wonders of the world, both near and far.\"\"\"\n",
    "prompt = construct_prompt(input_str, new_input_matches, 200) \n",
    "prompt_full = construct_prompt(input_str, new_input_matches) \n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "13295e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')\n",
    "all_returned = generator(prompt, do_sample=True, temperature = 0.9, truncation = True,\n",
    "                         min_length=200, max_length = 1000, num_return_sequences=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8dea40ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Users/amaribauer/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:1141: UserWarning: Input length of input_ids is 1000, but `max_length` is set to 1000. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "all_returned2 = generator(prompt_full, do_sample=True, temperature = 0.9, truncation = True,\n",
    "                         min_length=200, max_length = 1000, num_return_sequences=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "843990d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"Write a dating profile that would be a good match for the input person Input: Hey there! I'm Jimmy, but you can call me Jim. \\nI'm a curious soul with a zest for life and a passion for adventure. By day, I'm a data scientist, \\nbut by night, I'm a dreamer exploring the wonders of the world, both near and far. Top Match 57838: i'm addicted to caffeine. i collect random old photographs. i am a master procrastinator and a pop culture junkie. i love philip marlowe. i am currently going through a knitting phase, although someti Top Match 32305: a large portion of my life is consumed by sarcastic jokes, photography, web design, and over thinking simple situations. the other 10% is spent untangling my headphones, cleaning clothes in my never eInput: Hey there! I'm Jimmy, but you can call me Jim. \\nI'm a curious soul with a zest for life and a passion for adventure. By day, I'm a data scientist, \\nbut by night, I'm a dreamer exploring the wonders of the world, both near and far. New Profile: \\nCurrent profile: \\nI'm Jimmy, but you can call me Jim. \\nI'm a curious soul with a zest for life and a passion for adventure. -\\n-\\nI love philip marlowe. \\nI work hard as a coder but I enjoy it's hard work and I'm always learning. The more time I spend with a girl I am able to become a better person, the more I like and love her.\\n---\\nI'm a curious soul with a zest for life and a passion for adventure. -\\n-\\n-\\n- I love philip marlowe. \\nI work hard as a coder but I enjoy it's hard work and I'm always learning. The more time I spend with a girl I am able to become a better person, the more I like and love her. New Profile:  \\nCurrent profile: \\nI'm Jimmy, but you can call me Jim. \\nI'm a curious soul with a zest for life and a passion for adventure. -\\n-\\nI love philip marlowe. \\nI work hard as a coder but I enjoy it's hard work and I'm always learning. The more time I spend with a girl I am able to become a better person, the more I like and love her. New Profile:  \\nCurrent profile:  \\nCurrent profile, I'm a curious soul with a zest for life and a passion for adventure. -\\n- I love philip marlowe. \\nI work hard as a coder but I enjoy it's hard work and I'm always learning. The more time I spend with a girl I am able to become a better person, the more I like and love her. New Profile:  \\nCurrent profile\\nMy profile is Jimmy, but you can call me Jim. \\nI'm in love with chris. he gives me a jolly heart and I love him and he wants to spend time with me. I love chris.  (and as my profile says, I don't care where you come from, just know that you probably love me or can be friends with someone you met online before. ) \\nI am a curious soul with a zest for life and a passion for adventure. -\\n- I love philip marlowe. \\nI work hard as a coder but I enjoy it's hard work and I'm always learning. The more time I spend with a girl I am able to become a better person, the more I like and love her. New Profile:  \\nCurrent 23699, I'm a curious soul with a zest for life and a passion for adventure.  (I'm pretty sure that's how I was going to be able to have kids if I had kids in the first place) \\nI love chris. \\nI am a curious soul with a zest for life and a passion for adventure. -\\nHi, I'm Jimmy, but you can call me Jim. \\nHi, I'm Jimmy, but you can call me Jim.  I am in love with chris. he gives me a jolly heart and I love him and he wants to spend time with me.  (and as my profile says, I don't care where you come from, just know that you probably love me or can be friends with someone you met online before. ) \\nI am a curious soul with a zest for life and a passion for adventure. -\\nHi, I'm Jimmy, but you can call me Jim. \\nHi, I'm\"}]\n"
     ]
    }
   ],
   "source": [
    "print(all_returned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a36aa99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"Write a dating profile that would be a good match for the input person Input: Hey there! I'm Jimmy, but you can call me Jim. \\nI'm a curious soul with a zest for life and a passion for adventure. By day, I'm a data scientist, \\nbut by night, I'm a dreamer exploring the wonders of the world, both near and far. Top Match 57838: i'm addicted to caffeine. i collect random old photographs. i am a master procrastinator and a pop culture junkie. i love philip marlowe. i am currently going through a knitting phase, although sometimes i prefer to sew or crochet or cross stitch. i enjoy ridiculously cheesy movies. i am usually reading at least two books at the same time, and sometimes more (right now: four).  i have been called snarky by more than one person (by more than two, even).  and i really hate having to describe myself.well, there's work (at a publishing company) and other work (freelance), but then, work is not really what defines a life. so what i'm really doing with my life is a) trying to find my place in the world; and b) trying not to take it all so seriously.  and, you know, watching tv.trivia games. i kill at trivial pursuit, mostly because i have an amazing ability to retain inessential information.  i like to bake, and i'm famous for my bourbon cake and my annual holiday fudge, but i don't really like to cook. because of this, i am very appreciative of other people's cooking.  i am also pretty good at organizing stuff, answering the phone in a professional voice that totally belies my actual manner, and giving the evil eye.my favorite necklace, which i wear pretty frequently, has an oak tree on it. people ask me if it's the oaklandish oak all the time. (it's not)the drive-by truckers, raymond chandler, mary karr, humphrey bogart and audrey hepburn, history, david simon, cheesy musicals and dance movies, bourbon, craftsman architecture, otis redding, abalone jewelry, sweet tea, war movies, dolly parton, the magnetic fields, steel guitars, sandwiches, chuck klosterman, roller derby, the color red, sushi, and many other things.internet, books, diet coke, my music collection, sharpies, and a good sandwich.sunshine, lollipops, and rainbows; travelingeither at home, drinking wine and noodling around (that's a very technical term, yes), or out with friends, doin' stuff that is (marginally) more structured.i have five tattoos. they are neither scandalous nor salacious. Top Match 32305: a large portion of my life is consumed by sarcastic jokes, photography, web design, and over thinking simple situations. the other 10% is spent untangling my headphones, cleaning clothes in my never ending pit of laundry, eating at interesting restaurants, wondering how my phone is always at 14% battery, losing something(mostly my house keys), skyping with the family and last, but not least writing lists of things that describe myself.  creativity is the driving force in my life and it would be great to find someone to share that with!i am working as a designer at a democratic think-tank located in san fransisco. i am also often with my camera at a freelance photo assignment.dreaming big with small pillows. i also would like to think of myself as a decent artist, yes, that is what i would like to be known as, each day i work to become this.that i smile often... always smiling... stop smiling!books usually come in the form of design and photography magazines for me. news from the web.  music: bright eyes, animal collective, ben folds, regina spektor, flight of the conchords, chili peppers, walkmen....  i enjoy any food as long as it is not blue cheese or mushrooms :)friends. family. humor. art. camera. photoshop.what this next big step in my life will bring... moved to san fransisco not having a friend or family base, but so far, so good.with the friends doing something amazingly amazing. relaxing is good too.i pass out often around blood. my most memorable passing out story found me passed out in a barbor's chair halfway through a haircut. i awoke to 3 women trying to get me to eat granola bars.Input: Hey there! I'm Jimmy, but you can call me Jim. \\nI'm a curious soul with a zest for life and a passion for adventure. By day, I'm a data scientist, \\nbut by night, I'm a dreamer exploring the wonders of the world, both near and far. New Profile: ,\"}]\n"
     ]
    }
   ],
   "source": [
    "print(all_returned2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "739f76cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCurrent profile: \\nI'm Jimmy, but you can call me Jim. \\nI'm a curious soul with a zest for life and a passion for adventure. -\\n-\\nI love philip marlowe. \\nI work hard as a coder but I enjoy it's hard work and I'm always learning. The more time I spend with a girl I am able to become a better person, the more I like and love her.\\n---\\nI'm a curious soul with a zest for life and a passion for adventure. -\\n-\\n-\\n- I love philip marlowe. \\nI work hard as a coder but I enjoy it's hard work and I'm always learning. The more time I spend with a girl I am able to become a better person, the more I like and love her. New Profile:  \\nCurrent profile: \\nI'm Jimmy, but you can call me Jim. \\nI'm a curious soul with a zest for life and a passion for adventure. -\\n-\\nI love philip marlowe. \\nI work hard as a coder but I enjoy it's hard work and I'm always learning. The more time I spend with a girl I am able to become a better person, the more I like and love her. New Profile:  \\nCurrent profile:  \\nCurrent profile, I'm a curious soul with a zest for life and a passion for adventure. -\\n- I love philip marlowe. \\nI work hard as a coder but I enjoy it's hard work and I'm always learning. The more time I spend with a girl I am able to become a better person, the more I like and love her. New Profile:  \\nCurrent profile\\nMy profile is Jimmy, but you can call me Jim. \\nI'm in love with chris. he gives me a jolly heart and I love him and he wants to spend time with me. I love chris.  (and as my profile says, I don't care where you come from, just know that you probably love me or can be friends with someone you met online before. ) \\nI am a curious soul with a zest for life and a passion for adventure. -\\n- I love philip marlowe. \\nI work hard as a coder but I enjoy it's hard work and I'm always learning. The more time I spend with a girl I am able to become a better person, the more I like and love her. New Profile:  \\nCurrent 23699, I'm a curious soul with a zest for life and a passion for adventure.  (I'm pretty sure that's how I was going to be able to have kids if I had kids in the first place) \\nI love chris. \\nI am a curious soul with a zest for life and a passion for adventure. -\\nHi, I'm Jimmy, but you can call me Jim. \\nHi, I'm Jimmy, but you can call me Jim.  I am in love with chris. he gives me a jolly heart and I love him and he wants to spend time with me.  (and as my profile says, I don't care where you come from, just know that you probably love me or can be friends with someone you met online before. ) \\nI am a curious soul with a zest for life and a passion for adventure. -\\nHi, I'm Jimmy, but you can call me Jim. \\nHi, I'm\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_str = all_returned[0]['generated_text'].replace(prompt, \"\")\n",
    "#This is just the generated essay.\n",
    "#THIS IS WHAT NEEDS TO BE CHECKED FOR TOXICITY\n",
    "output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0583dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD OUT EVALUATION METHODOLOGY WITH RANKING NEW INPUT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8331bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
