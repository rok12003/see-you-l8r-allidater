{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchtext.vocab import GloVe\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the output from classifier and rename columns for clarity\n",
    "probabilities = pd.read_csv('classifier/classifier_outputs.csv', index_col=0).rename(columns = {'drugs': 'drugs_uses',\n",
    "                                                                                                'drugs.1': 'drugs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'age', 'status', 'sex', 'orientation', 'body_type', 'diet',\n",
       "       'drinks', 'drugs_uses', 'education', 'ethnicity', 'height', 'income',\n",
       "       'job', 'location', 'offspring', 'pets', 'religion', 'sign', 'smokes',\n",
       "       'speaks', 'essay0', 'food', 'kids', 'travel', 'drama', 'music', 'TV',\n",
       "       'comedies', 'movies', 'drinking', 'books', 'drugs', 'sentiment_label',\n",
       "       'sentiment_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look\n",
    "probabilities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in glove embeddings. The reason we're using glove embeddings is because not all interests are equally different.\n",
    "# For example, drinking and food are more similar than drama and food, so we want to account for that semantic similarity.\n",
    "glove = GloVe(name = \"6B\", dim = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(probabilities.columns[22:33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab for each possible interest\n",
    "vocab = defaultdict(lambda: glove['unknown'])  # Default to 'unknown' vector for missing words\n",
    "for name in names:\n",
    "    words = name.split()\n",
    "    vectors = [glove[word.lower()] for word in words if word.lower() in glove.stoi]\n",
    "    \n",
    "    # Average the vectors for words in the name if it's a compound, else just use the vector\n",
    "    if vectors:\n",
    "        vocab[name] = torch.mean(torch.stack(vectors), dim=0)\n",
    "    else:\n",
    "        vocab[name] = glove['unknown']  # Use 'unknown' vector if none of the words in the name are in GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for weighting the embedding vectors based on the input's probability of falling into that interest\n",
    "def get_weighted_vectors(row, vocab=vocab):\n",
    "    weighted_vectors = []\n",
    "    for col in names:\n",
    "        if col in vocab:\n",
    "            weighted_vector = row[col] * vocab[col]\n",
    "            weighted_vectors.append(weighted_vector)\n",
    "    \n",
    "    return sum(weighted_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for returning a list of cosine similarities between user interests and all possible matches' interests\n",
    "def compute_cosine_similarity(target_vector, vectors):\n",
    "    similarities = []\n",
    "    for vector in vectors:\n",
    "        similarity = 1 - cosine(target_vector, vector)  # 1 - cosine distance to get cosine similarity\n",
    "        similarities.append(similarity)\n",
    "    return similarities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it all together!\n",
    "def rank_matches(input_probabilities, pref_gender=False, pref_age_lower=False, pref_age_higher=False):\n",
    "    # First, let's filter the dataframe so we're only dealing with possible matches. For now, we're only looking at\n",
    "    # the user's gender preference and age preference, but that can be expanded.\n",
    "    #print(input_probabilities)\n",
    "    df_possible = probabilities.copy()\n",
    "    if pref_gender:\n",
    "        df_possible = df_possible.loc[df_possible.loc[:,'sex'] == pref_gender, :]\n",
    "    if pref_age_higher:\n",
    "        df_possible = df_possible[df_possible.loc[:, \"age\"] <= pref_age_higher]\n",
    "    if pref_age_lower:\n",
    "        df_possible = df_possible[df_possible.loc[:, \"age\"] >= pref_age_lower]\n",
    "\n",
    "    \n",
    "    # Create weighted vectors for all observations in the dataset\n",
    "    representation_vectors = df_possible.apply(lambda row: get_weighted_vectors(row), axis = 1)\n",
    "    weighted_user = get_weighted_vectors(input_probabilities)\n",
    "    # Compute the cosine similarity between the user's weighted embedding vector and all possible matches\n",
    "    cosine_similarities = compute_cosine_similarity(weighted_user, representation_vectors)\n",
    "    # Recover index to match back to original dataframe\n",
    "    similarity_scores = [(index, score) for index, score in enumerate(cosine_similarities)]\n",
    "    # Sort by similarity\n",
    "    ranked_similarity = sorted(similarity_scores, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    return ranked_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs_uses</th>\n",
       "      <th>education</th>\n",
       "      <th>...</th>\n",
       "      <th>drama</th>\n",
       "      <th>music</th>\n",
       "      <th>TV</th>\n",
       "      <th>comedies</th>\n",
       "      <th>movies</th>\n",
       "      <th>drinking</th>\n",
       "      <th>books</th>\n",
       "      <th>drugs</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32627</td>\n",
       "      <td>25</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>fit</td>\n",
       "      <td>anything</td>\n",
       "      <td>very often</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063269</td>\n",
       "      <td>0.042128</td>\n",
       "      <td>0.039525</td>\n",
       "      <td>0.037574</td>\n",
       "      <td>0.029011</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.017707</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.948390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33884</td>\n",
       "      <td>34</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016887</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.012192</td>\n",
       "      <td>0.050511</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.032730</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.997833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50509</td>\n",
       "      <td>26</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from two-year college</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076248</td>\n",
       "      <td>0.136479</td>\n",
       "      <td>0.087189</td>\n",
       "      <td>0.103010</td>\n",
       "      <td>0.046710</td>\n",
       "      <td>0.081643</td>\n",
       "      <td>0.037309</td>\n",
       "      <td>0.022735</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.983977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48305</td>\n",
       "      <td>41</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>gay</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from ph.d program</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168858</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>0.089926</td>\n",
       "      <td>0.074984</td>\n",
       "      <td>0.047286</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>0.121727</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.992873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28049</td>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6440</td>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>rarely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072007</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.163226</td>\n",
       "      <td>0.079852</td>\n",
       "      <td>0.057335</td>\n",
       "      <td>0.047112</td>\n",
       "      <td>0.111011</td>\n",
       "      <td>0.030546</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.995419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42908</td>\n",
       "      <td>34</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>graduated from ph.d program</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221974</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.031314</td>\n",
       "      <td>0.036303</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.018199</td>\n",
       "      <td>0.059223</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7571</td>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.155575</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.997934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37848</td>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>0.329929</td>\n",
       "      <td>0.013222</td>\n",
       "      <td>0.069344</td>\n",
       "      <td>0.109557</td>\n",
       "      <td>0.029009</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49365</td>\n",
       "      <td>32</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  age  status sex orientation       body_type               diet  \\\n",
       "0  32627   25  single   m    straight             fit           anything   \n",
       "1  33884   34  single   m    straight         average    mostly anything   \n",
       "2  50509   26  single   m    straight        athletic       mostly other   \n",
       "3  48305   41  single   m         gay         average                NaN   \n",
       "4  28049   29  single   m    straight        athletic    mostly anything   \n",
       "5   6440   29  single   f    straight             NaN  strictly anything   \n",
       "6  42908   34  single   m    straight        athletic    mostly anything   \n",
       "7   7571   29  single   m    straight  a little extra           anything   \n",
       "8  37848   29  single   m    straight        athletic                NaN   \n",
       "9  49365   32  single   m    straight         average    mostly anything   \n",
       "\n",
       "       drinks drugs_uses                          education  ...     drama  \\\n",
       "0  very often      never                                NaN  ...  0.063269   \n",
       "1    socially  sometimes     graduated from masters program  ...  0.016887   \n",
       "2    socially      never    graduated from two-year college  ...  0.076248   \n",
       "3    socially        NaN        graduated from ph.d program  ...  0.168858   \n",
       "4       often        NaN     graduated from masters program  ...       NaN   \n",
       "5      rarely        NaN  graduated from college/university  ...  0.072007   \n",
       "6    socially  sometimes        graduated from ph.d program  ...  0.221974   \n",
       "7    socially        NaN  graduated from college/university  ...  0.003763   \n",
       "8    socially      never     graduated from masters program  ...  0.027033   \n",
       "9    socially      never     graduated from masters program  ...       NaN   \n",
       "\n",
       "      music        TV  comedies    movies  drinking     books     drugs  \\\n",
       "0  0.042128  0.039525  0.037574  0.029011  0.025359  0.023555  0.017707   \n",
       "1  0.074945  0.012192  0.050511  0.013237  0.027108  0.032730  0.005736   \n",
       "2  0.136479  0.087189  0.103010  0.046710  0.081643  0.037309  0.022735   \n",
       "3  0.069260  0.089926  0.074984  0.047286  0.029727  0.121727  0.036615   \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "5  0.072581  0.163226  0.079852  0.057335  0.047112  0.111011  0.030546   \n",
       "6  0.032200  0.031314  0.036303  0.019470  0.018199  0.059223  0.022158   \n",
       "7  0.155575  0.003796  0.002200  0.001876  0.001531  0.003603  0.000765   \n",
       "8  0.329929  0.013222  0.069344  0.109557  0.029009  0.009380  0.007743   \n",
       "9       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "  sentiment_label sentiment_score  \n",
       "0        POSITIVE        0.948390  \n",
       "1        POSITIVE        0.997833  \n",
       "2        POSITIVE        0.983977  \n",
       "3        POSITIVE        0.992873  \n",
       "4        POSITIVE        0.999867  \n",
       "5        NEGATIVE        0.995419  \n",
       "6        POSITIVE        0.999723  \n",
       "7        POSITIVE        0.997934  \n",
       "8             NaN             NaN  \n",
       "9             NaN             NaN  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it out!\n",
    "\n",
    "ranked = rank_matches(probabilities.loc[8,:])#, pref_gender = \"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_indices = pd.DataFrame([tup[0] for tup in ranked[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_indices.to_csv('top5_indices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  4\n",
       "1  8\n",
       "2  9\n",
       "3  2\n",
       "4  5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
