{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchtext.vocab import GloVe\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the output from classifier and rename columns for clarity\n",
    "probabilities = pd.read_csv('classifier/classifier_outputs.csv', index_col=0).rename(columns = {'drugs': 'drugs_uses',\n",
    "                                                                                                'drugs.1': 'drugs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'age', 'status', 'sex', 'orientation', 'body_type', 'diet',\n",
       "       'drinks', 'drugs_uses', 'education', 'ethnicity', 'height', 'income',\n",
       "       'job', 'location', 'offspring', 'pets', 'religion', 'sign', 'smokes',\n",
       "       'speaks', 'essay0', 'travel', 'drama', 'kids', 'TV', 'music',\n",
       "       'comedies', 'drinking', 'movies', 'books', 'food', 'drugs', 'sequence',\n",
       "       'sentiment_label', 'sentiment_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look\n",
    "probabilities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in glove embeddings. The reason we're using glove embeddings is because not all interests are equally different.\n",
    "# For example, drinking and food are more similar than drama and food, so we want to account for that semantic similarity.\n",
    "glove = GloVe(name = \"6B\", dim = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(probabilities.columns[22:33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab for each possible interest\n",
    "vocab = defaultdict(lambda: glove['unknown'])  # Default to 'unknown' vector for missing words\n",
    "for name in names:\n",
    "    words = name.split()\n",
    "    vectors = [glove[word.lower()] for word in words if word.lower() in glove.stoi]\n",
    "    \n",
    "    # Average the vectors for words in the name if it's a compound, else just use the vector\n",
    "    if vectors:\n",
    "        vocab[name] = torch.mean(torch.stack(vectors), dim=0)\n",
    "    else:\n",
    "        vocab[name] = glove['unknown']  # Use 'unknown' vector if none of the words in the name are in GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for weighting the embedding vectors based on the input's probability of falling into that interest\n",
    "def get_weighted_vectors(row, vocab=vocab):\n",
    "    weighted_vectors = []\n",
    "    for col in names:\n",
    "        if col in vocab:\n",
    "            weighted_vector = row[col] * vocab[col]\n",
    "            weighted_vectors.append(weighted_vector)\n",
    "    \n",
    "    return sum(weighted_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for returning a list of cosine similarities between user interests and all possible matches' interests\n",
    "def compute_cosine_similarity(target_vector, vectors):\n",
    "    similarities = []\n",
    "    for vector in vectors:\n",
    "        similarity = 1 - cosine(target_vector, vector)  # 1 - cosine distance to get cosine similarity\n",
    "        similarities.append(similarity)\n",
    "    return similarities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it all together!\n",
    "def rank_matches(input_probabilities, pref_gender=False, pref_age_lower=False, pref_age_higher=False):\n",
    "    # First, let's filter the dataframe so we're only dealing with possible matches. For now, we're only looking at\n",
    "    # the user's gender preference and age preference, but that can be expanded.\n",
    "    df_possible = probabilities.copy()\n",
    "    if pref_gender:\n",
    "        df_possible = df_possible.loc[df_possible.loc[:,'sex'] == pref_gender, :]\n",
    "    if pref_age_higher:\n",
    "        df_possible = df_possible[df_possible.loc[:, \"age\"] <= pref_age_higher]\n",
    "    if pref_age_lower:\n",
    "        df_possible = df_possible[df_possible.loc[:, \"age\"] >= pref_age_lower]\n",
    "\n",
    "    \n",
    "    # Create weighted vectors for all observations in the dataset\n",
    "    representation_vectors = df_possible.apply(lambda row: get_weighted_vectors(row), axis = 1)\n",
    "    weighted_user = get_weighted_vectors(input_probabilities)\n",
    "\n",
    "    # Compute the cosine similarity between the user's weighted embedding vector and all possible matches\n",
    "    cosine_similarities = compute_cosine_similarity(weighted_user, representation_vectors)\n",
    "\n",
    "    # Recover index to match back to original dataframe\n",
    "    similarity_scores = [(index, score) for index, score in enumerate(cosine_similarities)]\n",
    "    # Sort by similarity\n",
    "    ranked_similarity = sorted(similarity_scores, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    return ranked_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs_uses</th>\n",
       "      <th>education</th>\n",
       "      <th>...</th>\n",
       "      <th>music</th>\n",
       "      <th>comedies</th>\n",
       "      <th>drinking</th>\n",
       "      <th>movies</th>\n",
       "      <th>books</th>\n",
       "      <th>food</th>\n",
       "      <th>drugs</th>\n",
       "      <th>sequence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5868</td>\n",
       "      <td>26</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077048</td>\n",
       "      <td>0.073351</td>\n",
       "      <td>0.066264</td>\n",
       "      <td>0.046497</td>\n",
       "      <td>0.046491</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.020955</td>\n",
       "      <td>i'm just a sweet, caring girl looking for what...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.997532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628</td>\n",
       "      <td>30</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>curvy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on masters program</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069811</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.046642</td>\n",
       "      <td>0.027142</td>\n",
       "      <td>0.030537</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>my attempt at nutshell-ing myself:  i'm califo...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49231</td>\n",
       "      <td>25</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>curvy</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057827</td>\n",
       "      <td>0.037907</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>0.026004</td>\n",
       "      <td>0.034496</td>\n",
       "      <td>0.017207</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>my name is katie - i grew up in loomis, ca - l...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44964</td>\n",
       "      <td>56</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027218</td>\n",
       "      <td>0.015264</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.218720</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>i'm independent, confident and self-sufficient...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41515</td>\n",
       "      <td>25</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252955</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.143121</td>\n",
       "      <td>0.119392</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>art, family, music, honest, friends, hate dram...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39287</td>\n",
       "      <td>27</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>0.013645</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>0.740993</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.011627</td>\n",
       "      <td>i'm a scientist, a financier, and an athlete. ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41044</td>\n",
       "      <td>30</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>gay</td>\n",
       "      <td>curvy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>0.031794</td>\n",
       "      <td>0.033540</td>\n",
       "      <td>0.012664</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>0.657713</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>i like this quote from devilicia:\"she is the c...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.996552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37621</td>\n",
       "      <td>62</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>college/university</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.027265</td>\n",
       "      <td>0.031049</td>\n",
       "      <td>0.028208</td>\n",
       "      <td>0.524672</td>\n",
       "      <td>0.019277</td>\n",
       "      <td>i have been distracted by the economy, recentl...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.923569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14971</td>\n",
       "      <td>40</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081742</td>\n",
       "      <td>0.066150</td>\n",
       "      <td>0.046778</td>\n",
       "      <td>0.071214</td>\n",
       "      <td>0.080555</td>\n",
       "      <td>0.051302</td>\n",
       "      <td>0.028376</td>\n",
       "      <td>i try not to sweat the small stuff, life is to...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30813</td>\n",
       "      <td>28</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>gay</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071772</td>\n",
       "      <td>0.096163</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>0.050686</td>\n",
       "      <td>0.061501</td>\n",
       "      <td>0.035486</td>\n",
       "      <td>0.030176</td>\n",
       "      <td>i don't think i can summarize myself. there ar...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.893676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  age  status sex orientation body_type             diet    drinks  \\\n",
       "0   5868   26  single   f    straight       NaN  mostly anything  socially   \n",
       "1    628   30  single   f    straight     curvy              NaN  socially   \n",
       "2  49231   25  single   f    straight     curvy  mostly anything  socially   \n",
       "3  44964   56  single   f    straight   average         anything  socially   \n",
       "4  41515   25  single   f    straight  athletic     mostly other  socially   \n",
       "5  39287   27  single   m    straight  athletic              NaN  socially   \n",
       "6  41044   30  single   f         gay     curvy              NaN  socially   \n",
       "7  37621   62  single   f    straight       fit              NaN  socially   \n",
       "8  14971   40  single   m    straight   average              NaN  socially   \n",
       "9  30813   28  single   m         gay   average  mostly anything  socially   \n",
       "\n",
       "  drugs_uses                          education  ...     music  comedies  \\\n",
       "0      never                                NaN  ...  0.077048  0.073351   \n",
       "1        NaN         working on masters program  ...  0.069811  0.003712   \n",
       "2        NaN      working on college/university  ...  0.057827  0.037907   \n",
       "3      never                                NaN  ...  0.027218  0.015264   \n",
       "4      never      working on college/university  ...  0.252955  0.000711   \n",
       "5      never  graduated from college/university  ...  0.025607  0.013645   \n",
       "6  sometimes  graduated from college/university  ...  0.025175  0.031794   \n",
       "7      never                 college/university  ...  0.033626  0.037356   \n",
       "8      never                                NaN  ...  0.081742  0.066150   \n",
       "9      never  graduated from college/university  ...  0.071772  0.096163   \n",
       "\n",
       "   drinking    movies     books      food     drugs  \\\n",
       "0  0.066264  0.046497  0.046491  0.046400  0.020955   \n",
       "1  0.004391  0.046642  0.027142  0.030537  0.002358   \n",
       "2  0.028851  0.026004  0.034496  0.017207  0.012556   \n",
       "3  0.010547  0.218720  0.008975  0.007405  0.006818   \n",
       "4  0.001258  0.143121  0.119392  0.004099  0.000282   \n",
       "5  0.009025  0.013625  0.740993  0.012322  0.011627   \n",
       "6  0.033540  0.012664  0.011132  0.657713  0.015320   \n",
       "7  0.027265  0.031049  0.028208  0.524672  0.019277   \n",
       "8  0.046778  0.071214  0.080555  0.051302  0.028376   \n",
       "9  0.044873  0.050686  0.061501  0.035486  0.030176   \n",
       "\n",
       "                                            sequence sentiment_label  \\\n",
       "0  i'm just a sweet, caring girl looking for what...        POSITIVE   \n",
       "1  my attempt at nutshell-ing myself:  i'm califo...        POSITIVE   \n",
       "2  my name is katie - i grew up in loomis, ca - l...        POSITIVE   \n",
       "3  i'm independent, confident and self-sufficient...        POSITIVE   \n",
       "4  art, family, music, honest, friends, hate dram...        POSITIVE   \n",
       "5  i'm a scientist, a financier, and an athlete. ...        POSITIVE   \n",
       "6  i like this quote from devilicia:\"she is the c...        POSITIVE   \n",
       "7  i have been distracted by the economy, recentl...        NEGATIVE   \n",
       "8  i try not to sweat the small stuff, life is to...        POSITIVE   \n",
       "9  i don't think i can summarize myself. there ar...        NEGATIVE   \n",
       "\n",
       "  sentiment_score  \n",
       "0        0.997532  \n",
       "1        0.998791  \n",
       "2        0.999646  \n",
       "3        0.999783  \n",
       "4        0.999570  \n",
       "5        0.999583  \n",
       "6        0.996552  \n",
       "7        0.923569  \n",
       "8        0.998430  \n",
       "9        0.893676  \n",
       "\n",
       "[10 rows x 36 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.9957047022899698),\n",
       " (4, 0.9528308092531714),\n",
       " (3, 0.9100180614878163),\n",
       " (2, 0.8981551340086066),\n",
       " (6, 0.856761621389742),\n",
       " (1, 0.8331191346904884),\n",
       " (5, 0.7973132590420293)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it out!\n",
    "\n",
    "rank_matches(probabilities.loc[8,:], pref_gender = \"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
